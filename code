##This document provides all commands and tools used to generate the data for the manuscript "Genomic investigations in animal enteric disease associated Clostridium perfringens"
##published in XXX. 

##The following tools were used on the UBELIX high performance computing of the University of Bern: 
##clinker (v0.0.29), 
##Flye (v.2.9.3-b1797), 
##LJA (v.0.2), 
##bcl2fastq conversion software (v2.20),
##ANIclustermap (v2.0.0), 
##VIBRANT (v1.2.1), 
##IGUA (v0.1.0), 
##clustal omega (v1.2.4), 
##BUSCO (v5.3.2), 
##SMRT Tools (v.13.0.0.207600), 
##GECCO (v0.9.10), 
##panaroo (v1.4.2), 
##IQ-tree (v2.0.3), 
##diamond (v0.9.13), 
##SPAdes (v.3.14.0) 

##These tools were used on the Galaxy server (https://usegalaxy.eu/): 
##BLAST+ (v2.14.1) with makeblastdb, tblastn, blastp and blastn; 
##HMMER (v3.3.2) with jackhmmer and hmmsearch. 

##Following tools were used via webbrowser: 
##SignalP (v6.0) (https://services.healthtech.dtu.dk/services/SignalP-6.0/),
##conserved domain database (https://www.ncbi.nlm.nih.gov/Structure/cdd/wrpsb.cgi), 
##AlphaFold3 server (https://alphafoldserver.com/welcome), 
##deepTMHMM (v.1.0.42) (https://dtu.biolib.com/DeepTMHMM), 
##HHpred (https://toolkit.tuebingen.mpg.de/tools/hhpred), 
##antiSMASH (v8.0) (https://antismash.secondarymetabolites.org/#!/start),
##RiPPMiner (http://www.nii.ac.in/rippminer.html), 

##Invidiual codes
##clinker
clinker -p --dont_set_origin

##ANIclustermap
ANIclustermap -i path/to/plasmids_fna -t 3  -o plasmids_ani --annotation
##the created newick file was used as input for iTOL

##clustal omega
##sequence variants defined as deviation from wildtypesequence (V1) were determined manually in the resulting pile of alignments
clustalo --infile path/toxin_sequences_fasta --threads 2 --outfmt clustal --resno --outfile --pileup  --seqtype DNA

##GECCO
gecco run --genome concataned_gbk_file.txt --cds-feature CDS -o

##IGUA
igua --clustering-method complete --clustering-distance 0.5

##diamond
pip install numpy
pip install rich
pip install pandas
pip install gb-io
eval "$(conda shell.bash hook)"
conda activate diamond
python aci.py -q path/to/concatenated_GECCO_output -t mibig.gbk -o

###aci.py
import argparse
import dataclasses
import io
import itertools
import os
import tempfile
import subprocess
import multiprocessing.pool
import typing

import gb_io
import numpy
import rich.panel
import rich.progress
import pandas

# sys.path.insert(0, os.path.abspath(os.path.join(__file__, "..", "..", "..", "..")))
# import chamois.orf
# from chamois.model import ClusterSequence
# from chamois.cli._common import find_proteins

@dataclasses.dataclass
class Cluster:
    record: gb_io.Record

@dataclasses.dataclass
class Protein:
    id: str
    sequence: str
    cluster: Cluster

def extract_proteins(cluster: Cluster) -> typing.Iterator[Protein]:
    i = 1
    for feature in cluster.record.features:
        if feature.kind == "CDS":
            qualifiers = {q.key:q.value for q in feature.qualifiers}
            try:
                yield Protein(f"{cluster.record.name}_{i}", qualifiers["translation"], cluster)
                i += 1
            except KeyError:
                pass


parser = argparse.ArgumentParser()
parser.add_argument("-q", "--query", required=True)
parser.add_argument("-t", "--target", required=True)
parser.add_argument("-o", "--output", required=True)
parser.add_argument("-j", "--jobs", type=int)
args = parser.parse_args()

# run many-to-many comparison
with tempfile.TemporaryDirectory() as dst:

    with rich.progress.Progress() as progress:
        # load query records
        with progress.open(args.query, "r", description=f"[bold blue]{'Loading':>12}[/] queries") as src:
            query_records = {record.name: Cluster(record) for record in gb_io.iter(src)}
            query_ids = sorted(query_records)
            query_indices = {name:i for i, name in enumerate(query_ids)}
        # load target records
        with progress.open(args.target, "r", description=f"[bold blue]{'Loading':>12}[/] targets") as src:
            target_records = {record.name:Cluster(record) for record in gb_io.iter(src)}
            target_ids = sorted(target_records)
            target_indices = {name:i for i, name in enumerate(target_ids)}

        # find genes
        progress.console.print(f"[bold blue]{'Finding':>12}[/] genes in input records")
        with multiprocessing.pool.ThreadPool(args.jobs) as pool:
            query_genes = [gene for genes in progress.track(pool.imap(extract_proteins, query_records.values()), total=len(query_records), description=f"[bold blue]{'Processing':>12}[/] queries") for gene in genes]
            target_genes = [gene for genes in progress.track(pool.imap(extract_proteins, target_records.values()), total=len(target_records), description=f"[bold blue]{'Processing':>12}[/] targets") for gene in genes]

        # write target genes
        db_faa = os.path.join(dst, "db.faa")
        with open(db_faa, "w") as f:
            for protein in progress.track(target_genes, description=f"[bold blue]{'Writing':>12}[/] targets"):
                f.write(f">{protein.id}\n")
                f.write(f"{protein.sequence.rstrip('*')}\n")

    # make blastd
    rich.print(f"[bold blue]{'Making':>12}[/] BLASTp database")
    db_filename = os.path.join(dst, "db.db")
    proc = subprocess.run([
        "diamond",
        "makedb",
        "--in",
        db_faa,
        "--db",
        db_filename,
        "--tmpdir",
        dst,
        "--threads",
        str(args.jobs or os.cpu_count())
    ], capture_output=True)
    if proc.returncode != 0:
        rich.print(rich.panel.Panel(proc.stderr.decode()))
    proc.check_returncode()

    # write query records
    query_filename = os.path.join(dst, "query.faa")
    with open(query_filename, "w") as f:
        for protein in progress.track(query_genes, description=f"[bold blue]{'Writing':>12}[/] queries"):
            f.write(f">{protein.id}\n")
            f.write(f"{protein.sequence.rstrip('*')}\n")

    # run BLASTn
    rich.print(f"[bold blue]{'Running':>12}[/] BLASTp with DIAMOND")
    proc = subprocess.run([
        "diamond",
        "blastp",
        "--query",
        query_filename,
        "--db",
        db_filename,
        "--threads",
        str(args.jobs or os.cpu_count()),
        "--outfmt",
        "6",
        "--max-target-seqs",
        str(len(target_ids)),
        "--tmpdir",
        dst,
    ], capture_output=True)
    if proc.returncode != 0:
        rich.print(rich.panel.Panel(proc.stderr.decode()))
    proc.check_returncode()

    hits = pandas.read_table(
        io.BytesIO(proc.stdout),
        comment="#",
        header=None,
        index_col=None,
        names=[
            "query_protein",
            "target_protein",
            "identity",
            "alilen",
            "mismatches",
            "gapopens",
            "qstart",
            "qend",
            "sstart",
            "send",
            "evalue",
            "bitscore"
        ]
    )
    hits["query_cluster"] = hits["query_protein"].str.rsplit("_", n=1).str[0]
    hits["target_cluster"] = hits["target_protein"].str.rsplit("_", n=1).str[0]
    hits["query_index"] = hits["query_cluster"].map(query_indices.__getitem__)
    hits["target_index"] = hits["target_cluster"].map(target_indices.__getitem__)

    # only keep one hit per query protein per target cluster
    hits = (
        hits
            .sort_values(["query_protein", "bitscore"])
            .drop_duplicates(["query_protein", "target_cluster"], keep="last")
    )

    # compute identity
    identity = numpy.zeros((len(query_records), len(target_records)), dtype=numpy.float_)
    for row in hits.itertuples():
        identity[row.query_index, row.target_index] += row.identity * row.alilen / 100.0

    # normalize by query length
    for i, query_id in enumerate(query_ids):
        query_length = sum(
            len(protein.sequence)
            for protein in query_genes
            if protein.cluster.record.name == query_id
        )
        if query_length > 0:
            identity[i] /= query_length

    # make distances symmetric
    identity = numpy.clip(identity, 0, 1)
    rows = []
    for i, query_id in enumerate(query_ids):
        target_indices = numpy.argsort(identity[i])[-3:]
        for j in reversed(target_indices):
            rows.append({"query_cluster": query_id, "target_cluster": target_ids[j], "weighted_identity": identity[i, j]})

##panaroo and iqtree
eval "$(conda shell.bash hook)"
conda activate "panaroo"
panaroo -i -o --clean-mode strict --remove-invalid-genes --core_threshold 0.95 -a core
iqtree -s core_gene_alignment_filtered.aln -m GTR+F+R2 -B 1000

##jackHMMER
jackhmmer -A --tblout --chkhmm  --domtblout   input.txt uniprot_trembl.fasta

##hmmsearch
## profile 5 was used in hmmsearch against a concatenated protein list of all 619 genomes
hmmsearch -A   --cpu 5 --tblout  --domtblout  profile-5.hmm input.faa
## all hits were analyzed using excel. Hits with e-value >0.05 were discarded. 

##makeblastdb
python /opt/galaxy/shed_tools/toolshed.g2.bx.psu.edu/repos/devteam/ncbi_blast_plus/cbf3f518b668/ncbi_blast_plus/tools/ncbi_blast_plus/check_no_duplicates.py '/data/dnb09/galaxy_db/files/d/8/6/dataset_d8626a25-4d60-4e14-aa3b-59f6efc9f9ed.dat' && cat '/data/dnb09/galaxy_db/files/d/8/6/dataset_d8626a25-4d60-4e14-aa3b-59f6efc9f9ed.dat' | makeblastdb -out '/data/jwd02f/main/068/027/68027177/outputs/dataset_d3d07511-de2d-4bbd-ba21-748b8f5e88d0_files/blastdb' -blastdb_version 4  -hash_index -in - -title 'BLAST Database' -dbtype nucl > '/data/jwd02f/main/068/027/68027177/outputs/dataset_d3d07511-de2d-4bbd-ba21-748b8f5e88d0.dat'

##tblastn
tblastn  -query -db -task tblastn -evalue 0.001 -out -outfmt '6 std sallseqid score nident positive gaps ppos qframe sframe qseq sseq qlen slen salltitles'  -num_threads -db_gencode 1 -seg yes  -max_target_seqs '1000' -max_hsps '1' -qcov_hsp_perc '80.0'
##The resulting output file was then manually analyzed using excel. Only hits with >80% (90%) query/subject sequence identity and >95 and <105% query/subject sequnce length were considered real hits.  

##This is a script to create a toxin presence/absence matrix from an tblastn curated output. 
##two colums. left toxin, right identifier. identifier should be only the genome name without gene locus.  

#!/bin/bash


input_file="input.txt"
output_file="presence_absence_matrix.txt"

awk '
{
  strains[$1] = 1
  proteins[$2] = 1
  matrix[$1,$2] = 1
}
END {
  printf "\t"
  for (protein in proteins) {
    printf "%s\t", protein
  }
  print ""
  
  for (strain in strains) {
    printf "%s", strain
    for (protein in proteins) {
      if ((strain, protein) in matrix) {
        printf "\t1"
      } else {
        printf "\t-1"
      }
    }
    print ""
  }
}
' "$input_file" > "$output_file"

echo "Presence/absence matrix saved as $output_file."

##Figures
##Figure 1B
# Load required packages
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(progress)
library(patchwork)
library(minpack.lm)

# === Step 1: Load gene presence/absence matrix ===
gpa <- read_csv("path/to/panaroo/gene_presence_absence.csv")
presence_data <- gpa[, 4:ncol(gpa)]
presence_matrix <- presence_data != ""
n_genomes <- ncol(presence_matrix)
n_reps <- 30

# === Step 2: Initialize matrices for rarefaction ===
pan_matrix <- matrix(0, nrow = n_reps, ncol = n_genomes)
core_matrix <- matrix(0, nrow = n_reps, ncol = n_genomes)
pb <- progress_bar$new(format = "  Rarefying [:bar] :percent ETA: :eta", total = n_reps)

# === Step 3: Rarefaction replicates ===
set.seed(42)
for (rep in 1:n_reps) {
  genome_order <- sample(colnames(presence_matrix))
  for (i in 1:n_genomes) {
    subset_matrix <- presence_matrix[, genome_order[1:i], drop = FALSE]
    gene_counts <- rowSums(subset_matrix, na.rm = TRUE)
    pan_matrix[rep, i] <- sum(gene_counts >= 1)
    core_matrix[rep, i] <- sum(gene_counts == i)
  }
  pb$tick()
}

# === Step 4: Summarize results ===
pan_mean <- colMeans(pan_matrix)
pan_sd <- apply(pan_matrix, 2, sd)
core_mean <- colMeans(core_matrix)
core_sd <- apply(core_matrix, 2, sd)

# === Step 5: New gene discovery ===
new_gene_matrix <- pan_matrix
for (i in 2:ncol(pan_matrix)) {
  new_gene_matrix[, i] <- pan_matrix[, i] - pan_matrix[, i - 1]
}
new_gene_matrix[, 1] <- pan_matrix[, 1]
new_gene_mean <- colMeans(new_gene_matrix)
new_gene_sd <- apply(new_gene_matrix, 2, sd)

# === Step 6: Build combined data frame for plotting ===
plot_df <- data.frame(
  NumGenomes = 1:n_genomes,
  PanMean = pan_mean,
  PanSD = pan_sd,
  CoreMean = core_mean,
  CoreSD = core_sd,
  NewGenesMean = new_gene_mean,
  NewGenesSD = new_gene_sd
)

# === Step 7: Prepare data for plotting with consistent aesthetics ===
long_df <- plot_df %>%
  select(NumGenomes, PanMean, CoreMean) %>%
  rename(Pan_genome = PanMean, Core_genome = CoreMean) %>%
  pivot_longer(cols = c(Pan_genome, Core_genome),
               names_to = "Category", values_to = "Genes")

long_sd <- plot_df %>%
  select(NumGenomes, PanSD, CoreSD) %>%
  rename(Pan_genome = PanSD, Core_genome = CoreSD) %>%
  pivot_longer(cols = c(Pan_genome, Core_genome),
               names_to = "Category", values_to = "SD")

long_df <- left_join(long_df, long_sd, by = c("NumGenomes", "Category"))

# === Step 8: Fit Heaps' Law model ===
heaps_model <- nlsLM(PanMean ~ k * NumGenomes^alpha,
                     data = plot_df,
                     start = list(k = 1000, alpha = 0.5))
alpha_val <- round(coef(heaps_model)["alpha"], 3)

# === Step 9: Plot p1 — Rarefied pan/core genome curves ===
p1 <- ggplot(long_df, aes(x = NumGenomes, y = Genes, color = Category, fill = Category)) +
  geom_ribbon(aes(ymin = Genes - SD, ymax = Genes + SD), alpha = 0.3, color = NA) +
  geom_line(size = 1.2) +
  scale_color_manual(
    values = c("Pan_genome" = "darkorange", "Core_genome" = "seagreen"),
    labels = c("Pan-genome", "Core genome"),
    breaks = c("Pan_genome", "Core_genome")
  ) +
  scale_fill_manual(
    values = c("Pan_genome" = "darkorange", "Core_genome" = "seagreen"),
    labels = c("Pan-genome", "Core genome"),
    breaks = c("Pan_genome", "Core_genome")
  ) +
  scale_x_continuous(
    limits = c(0, max(plot_df$NumGenomes)),
    breaks = seq(0, max(plot_df$NumGenomes), by = 100)
  ) +
  labs(
    title = "Rarefied Pan and Core Genome Curve",
    x = "Number of genomes",
    y = "Number of genes",
    color = "Category",
    fill = "Category"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    legend.key.size = unit(0.8, "lines")
  )

# === Step 10: Plot p3 — New genes per genome ===
p3 <- ggplot(plot_df, aes(x = NumGenomes, y = NewGenesMean)) +
  geom_line(color = "blue", size = 1.2, alpha = 0.6) +
  geom_ribbon(aes(ymin = NewGenesMean - NewGenesSD,
                  ymax = NewGenesMean + NewGenesSD),
              fill = "blue", alpha = 0.2) +
  scale_x_continuous(
    limits = c(0, max(plot_df$NumGenomes)),
    breaks = seq(0, max(plot_df$NumGenomes), by = 100)
  ) +
  labs(
    title = "Empirical New Gene Discovery",
    subtitle = paste0("Fitted Heaps’ α = ", alpha_val),
    x = "Number of genomes",
    y = "New genes per genome"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")

# === Step 11: Combine and export ===
final_plot <- p1 + p3 + plot_layout(widths = c(1, 1))
final_plot

##Figure 1C
# Load libraries
library(dplyr)
library(ggplot2)
library(ggpubr)

# Step 1: Process input data
# Assuming Supplementary_table is already loaded
Supplementary_table <- Supplementary_table %>%
  mutate(
    # Recode assembly status
    assembly_status = case_when(
      Level %in% c("Complete", "Chromosome") ~ "Complete",
      Level %in% c("Contig", "Scaffold") ~ "Draft",
      TRUE ~ NA_character_
    ),
    # Recode source
    source = case_when(
      Own == "Yes" ~ "New sequences",
      Own == "No" ~ "Public sequences",
      TRUE ~ NA_character_
    ),
    # Create combined group label for x-axis
    group = paste(source, assembly_status, sep = ": ")
  ) %>%
  filter(!is.na(assembly_status), !is.na(source), !is.na(Size))

# Step 2: Define comparisons
comparisons <- list(
  c("New sequences: Draft", "New sequences: Complete"),
  c("Public sequences: Draft", "Public sequences: Complete"),
  c("New sequences: Draft", "Public sequences: Draft"),
  c("New sequences: Complete", "Public sequences: Complete")
)

# Step 3: Final plot
ggplot(Supplementary_table, aes(x = group, y = Size, fill = assembly_status)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(
    color = "black",
    position = position_jitter(width = 0.2),
    size = 1.5,
    alpha = 0.6
  ) +
  stat_summary(
    aes(group = group),
    fun = median,
    geom = "crossbar",
    width = 0.5,
    color = "black",
    fatten = 2
  ) +
  stat_compare_means(comparisons = comparisons, method = "wilcox.test", label = "p.format") +
  scale_fill_manual(values = c("Draft" = "#2BA2A6", "Complete" = "#D72638")) +
  scale_x_discrete(labels = c(
    "New sequences: Draft" = "New sequences",
    "New sequences: Complete" = "New sequences",
    "Public sequences: Draft" = "Public sequences",
    "Public sequences: Complete" = "Public sequences"
  )) +
  labs(
    title = "Genome Size Comparison",
    x = "Genome Source",
    y = "Genome Size (Mb)",
    fill = "Assembly Status"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 0.5),
    legend.position = "right"
  )

##Figure 3A
# Load required libraries
library(tidyverse)

# === Step 1: Load and filter data ===
df <- Supplementary_table %>%
    filter(Toxinotype %in% c("A", "C", "D", "E", "F"))

# === Step 2: Count isolates by plasmid amount and toxinotype ===
plasmid_distribution <- df %>%
    count(amount, Toxinotype, name = "Occurrences")

# === Step 3: Define distinct colors for toxinotypes ===
tox_colors <- c(
    "A" = "#E41A1C",  # Red
    "C" = "#377EB8",  # Blue
    "D" = "#4DAF4A",  # Green
    "E" = "#984EA3",  # Purple
    "F" = "#FF7F00"   # Orange
)

# === Step 4: Create the plot ===
plot_stacked <- ggplot(plasmid_distribution, aes(x = amount, y = Occurrences, fill = Toxinotype)) +
    geom_bar(stat = "identity") +  # stacked bars by default
    scale_fill_manual(values = tox_colors) +
    scale_x_continuous(breaks = 0:10, expand = expansion(mult = c(0, 0.05))) +
    labs(
        x = "Total Number of Plasmids per Isolate",
        y = "Number of Isolates",
        fill = "Toxinotype"
    ) +
    theme_minimal(base_size = 18) +
    theme(
        legend.position = "inside",
        legend.position.inside = c(0.98, 0.98),
        legend.justification = c("right", "top"),
        legend.direction = "vertical",
        legend.title = element_text(size = 18),
        legend.text = element_text(size = 18),
        legend.background = element_rect(fill = "white", color = NA),
        
        # Make everything else white
        panel.background = element_rect(fill = "white", color = NA),
        plot.background = element_rect(fill = "white", color = NA),
        panel.grid = element_line(color = "grey90"),
        
        # Customize axis fonts
        axis.title = element_text(size = 16, face = "bold"),
        axis.text = element_text(size = 16)
    )

# === Step 5: Show the plot ===
print(plot_stacked)

##Figure 3B
library(ggplot2)    # for plotting
library(ggbreak)    # for broken y-axis
library(dplyr)      # for summary statistics and data wrangling


# New custom order
ordered_categories <- c("TCP", "PCP", "BCP", "BaCP", "TeCP", "piP404", "phage-like", "small", "unclassified")

# Apply factor levels in this order
Supplementary_table$Category <- factor(Supplementary_table$Category, levels = ordered_categories)

# Also make sure summary tables use the same order
summary_stats <- Supplementary_table %>%
    group_by(Category) %>%
    summarize(
        Q2 = quantile(Size, 0.25),
        Median = median(Size),
        Q3 = quantile(Size, 0.75)
    ) %>%
    arrange(factor(Category, levels = ordered_categories))

highlighted_medians <- summary_stats %>% filter(Category %in% c("BCP", "TeCP"))
default_medians     <- summary_stats %>% filter(!Category %in% c("BCP", "TeCP"))

# Define colors (unchanged)
custom_colors <- c(
    "TCP" = "#469990",
    "PCP" = "#42d4f4",
    "BCP" = "#4363d8",
    "BaCP" = "#e6194B",
    "TeCP" = "#f032e6",
    "piP404" = "#fffac8",
    "phage-like" = "#aaffc3",
    "small" = "#dcbeff",
    "unclassified" = "#a9a9a9"
)

# Plot
p <- ggplot(Supplementary_table, aes(x = Category, y = Size, fill = Category)) +
    geom_violin(trim = FALSE, width = 1, scale = "width", color = "black", alpha = 1) +
    geom_jitter(width = 0.3, color = "black", size = 0.7, alpha = 0.7) +
    geom_errorbar(
        data = summary_stats,
        mapping = aes(x = Category, ymin = Q2, ymax = Q3),
        width = 0.2,
        color = "black",
        linewidth = 1.2,
        inherit.aes = FALSE
    ) +
    geom_crossbar(
        data = default_medians,
        mapping = aes(x = Category, y = Median, ymin = Median, ymax = Median),
        width = 0.5,
        color = "black",
        linewidth = 0.9,
        inherit.aes = FALSE
    ) +
    geom_crossbar(
        data = highlighted_medians,
        mapping = aes(x = Category, y = Median, ymin = Median, ymax = Median, fill = Category),
        width = 0.5,
        color = "black",
        linewidth = 1.2,
        inherit.aes = FALSE
    ) +
    scale_fill_manual(values = custom_colors) +
    theme_minimal(base_size = 14) +
    theme(
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.line.y = element_line(color = "black", linewidth = 0.8),
        axis.ticks.y = element_line(color = "black"),
        panel.grid.major.x = element_blank()
    ) +
    labs(
        x = "Plasmid Category",
        y = "Plasmid Size (kb)"
    )

# Final plot with axis break
p + scale_y_break(c(200, 800), scales = 0.5)
